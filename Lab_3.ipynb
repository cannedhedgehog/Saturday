{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvnKJNlrNPJ6dQvxtewBnh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cannedhedgehog/Saturday/blob/main/Lab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "U-Ey19SQova1"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция активации (сигмоида)"
      ],
      "metadata": {
        "id": "yEx5rMe-qT-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "apr1n0uPpFH-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Производная сигмоиды для обратного распространения"
      ],
      "metadata": {
        "id": "cCVW8vFTqdKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "rk3Sk0j8pG_N"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот класс создаёт простую нейросеть с одним скрытым слоем, где можно: задать количество нейронов в скрытом слое, обучить сеть на примере, получать предсказания"
      ],
      "metadata": {
        "id": "RqKB-uaaq4f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        \"\"\"\n",
        "        Конструктор класса NeuralNetwork.\n",
        "\n",
        "        Аргументы:\n",
        "        input_size  - количество входных нейронов (размер входного вектора).\n",
        "        hidden_size - количество нейронов в скрытом слое (определяет сложность модели).\n",
        "\n",
        "        Внутри:\n",
        "        - Создаются и инициализируются случайные веса для входного и скрытого слоя.\n",
        "        - Создаются смещения (bias) для скрытого и выходного слоя, инициализированные нулями.\n",
        "        \"\"\"\n",
        "\n",
        "        self.input_size = input_size  # Количество входных признаков\n",
        "        self.hidden_size = hidden_size  # Количество нейронов в скрытом слое\n",
        "\n",
        "        # Матрица весов от входного слоя к скрытому (размер input_size x hidden_size)\n",
        "        self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
        "\n",
        "        # Матрица весов от скрытого слоя к выходному (размер hidden_size x 1)\n",
        "        self.weights_hidden_output = np.random.randn(hidden_size, 1)\n",
        "\n",
        "        # Смещения для скрытого слоя (размер 1 x hidden_size, т.к. один вектор смещения для всех примеров)\n",
        "        self.bias_hidden = np.zeros((1, hidden_size))\n",
        "\n",
        "        # Смещение для выходного слоя (размер 1 x 1, т.к. всего один выход)\n",
        "        self.bias_output = np.zeros((1, 1))\n",
        "\n",
        "    def feedforward(self, X):\n",
        "        \"\"\"\n",
        "        Прямой проход (forward propagation) через сеть.\n",
        "\n",
        "        Аргумент:\n",
        "        X - входной массив размерностью (количество примеров x input_size)\n",
        "\n",
        "        Внутри:\n",
        "        1. Умножаем входные данные на веса, прибавляем смещение (X * W + b)\n",
        "        2. Применяем сигмоидную функцию активации для скрытого слоя.\n",
        "        3. Повторяем процесс для выходного слоя.\n",
        "\n",
        "        Возвращает:\n",
        "        - Выходное значение после применения сигмоидной функции.\n",
        "        \"\"\"\n",
        "\n",
        "        # Расчёт взвешенной суммы на скрытом слое: X * W + b\n",
        "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "\n",
        "        # Применяем сигмоидную функцию активации\n",
        "        self.hidden_output = sigmoid(self.hidden_input)\n",
        "\n",
        "        # Расчёт взвешенной суммы на выходном слое\n",
        "        self.final_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "\n",
        "        # Применяем сигмоидную функцию активации на выходе\n",
        "        return sigmoid(self.final_input)\n",
        "\n",
        "    def train(self, X, y, epochs=1000, lr=0.1):\n",
        "        \"\"\"\n",
        "        Обучение модели с помощью обратного распространения ошибки (Backpropagation).\n",
        "\n",
        "        Аргументы:\n",
        "        X      - входные данные (размерность: количество примеров x input_size)\n",
        "        y      - целевые значения (размерность: количество примеров x 1)\n",
        "        epochs - количество эпох (сколько раз обновляем веса)\n",
        "        lr     - скорость обучения (learning rate)\n",
        "\n",
        "        Внутри:\n",
        "        1. Выполняется прямой проход.\n",
        "        2. Вычисляется ошибка между предсказанием и целевыми значениями.\n",
        "        3. Производится обратное распространение ошибки:\n",
        "           - Градиент выхода (как сильно нужно скорректировать выход).\n",
        "           - Градиент скрытого слоя (как сильно скорректировать скрытые нейроны).\n",
        "        4. Обновляются веса и смещения по методу градиентного спуска.\n",
        "        \"\"\"\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            # 1. Прямой проход: получаем предсказание сети\n",
        "            output = self.feedforward(X)\n",
        "\n",
        "            # 2. Вычисление ошибки (разница между истинным значением y и предсказанным output)\n",
        "            error = y - output\n",
        "\n",
        "            # 3. Вычисляем градиент для выходного слоя (производная сигмоиды * ошибка)\n",
        "            d_output = error * sigmoid_derivative(output)\n",
        "\n",
        "            # 4. Ошибка скрытого слоя (как сильно скрытый слой влияет на конечный результат)\n",
        "            error_hidden = d_output.dot(self.weights_hidden_output.T)\n",
        "\n",
        "            # 5. Градиент скрытого слоя (производная сигмоиды * ошибка скрытого слоя)\n",
        "            d_hidden = error_hidden * sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "            # 6. Обновление весов с учётом градиента и скорости обучения:\n",
        "            #    - Весы между скрытым и выходным слоем\n",
        "            #    - Весы между входным и скрытым слоем\n",
        "            self.weights_hidden_output += self.hidden_output.T.dot(d_output) * lr\n",
        "            self.weights_input_hidden += X.T.dot(d_hidden) * lr\n",
        "\n",
        "            # 7. Обновление смещений\n",
        "            self.bias_output += np.sum(d_output, axis=0, keepdims=True) * lr\n",
        "            self.bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * lr\n"
      ],
      "metadata": {
        "id": "Qikv3j7gqJJG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем искусственный табличный датасет\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # XOR-проблема\n",
        "y = np.array([[0], [1], [1], [0]])  # Ожидаемый выход"
      ],
      "metadata": {
        "id": "LkCB0EG-pliV"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем и обучаем сеть (меняя значение hidden_size задаем колличество нейронов)\n",
        "nn = NeuralNetwork(input_size=2, hidden_size=4)\n",
        "nn.train(X, y, epochs=5000, lr=0.1)"
      ],
      "metadata": {
        "id": "gapsFlWCpov2"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяем предсказания (Вход: [0 1] -> Выход: [0.98]  (≈ 1))\n",
        "for i in X:\n",
        "    print(f\"Вход: {i}, Выход: {nn.feedforward(i)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJflADQTpqLH",
        "outputId": "823efb76-ee8c-4d24-8edc-f3aa57f7a999"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вход: [0 0], Выход: [[0.05602212]]\n",
            "Вход: [0 1], Выход: [[0.9217298]]\n",
            "Вход: [1 0], Выход: [[0.91688698]]\n",
            "Вход: [1 1], Выход: [[0.10003555]]\n"
          ]
        }
      ]
    }
  ]
}