{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTMHUcxPF/BUjGLmQyr/rE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cannedhedgehog/Saturday/blob/main/4_1_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "9IcBe0b3viiW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гиперпараметры"
      ],
      "metadata": {
        "id": "rLMfcbAfvkJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"hellohellohello\"\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "block_size = 4\n",
        "n_embd = 16\n",
        "learning_rate = 0.1\n",
        "epochs = 500"
      ],
      "metadata": {
        "id": "kZA7rmJzvmwO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кодировка"
      ],
      "metadata": {
        "id": "UWIQNdyJvop_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for ch, i in stoi.items()}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])"
      ],
      "metadata": {
        "id": "Arn_wZ_mvq__"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данные"
      ],
      "metadata": {
        "id": "6-FCrgQKvtIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = encode(text)\n",
        "X, Y = [], []\n",
        "for i in range(len(data) - block_size):\n",
        "    X.append(data[i:i+block_size])\n",
        "    Y.append(data[i+block_size])\n",
        "X = np.array(X)  # (N, T)\n",
        "Y = np.array(Y)  # (N,)"
      ],
      "metadata": {
        "id": "VWeL2xCjvs0R"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры"
      ],
      "metadata": {
        "id": "HnBdLc1Wv2fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "token_embedding_table = np.random.randn(vocab_size, n_embd) * 0.01  # (vocab, C)\n",
        "W1 = np.random.randn(block_size * n_embd, vocab_size) * 0.01  # (T*C, vocab)"
      ],
      "metadata": {
        "id": "xlkrxvGIv3oB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение"
      ],
      "metadata": {
        "id": "5lmie9y2v4Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    # Прямой проход\n",
        "    x_emb = token_embedding_table[X]  # (B, T, C)\n",
        "    x_flat = x_emb.reshape(x_emb.shape[0], -1)  # (B, T*C)\n",
        "    logits = x_flat @ W1  # (B, vocab)\n",
        "\n",
        "    # Softmax\n",
        "    logits -= np.max(logits, axis=1, keepdims=True)\n",
        "    probs = np.exp(logits)\n",
        "    probs /= probs.sum(axis=1, keepdims=True)\n",
        "\n",
        "    # Loss\n",
        "    loss = -np.log(probs[np.arange(len(Y)), Y]).mean()\n",
        "    if epoch % 50 == 0 or epoch == epochs - 1:\n",
        "        print(f\"Epoch {epoch:3d} | Loss: {loss:.4f}\")\n",
        "\n",
        "    # Обратное распространение\n",
        "    dlogits = probs\n",
        "    dlogits[np.arange(len(Y)), Y] -= 1\n",
        "    dlogits /= len(Y)\n",
        "\n",
        "    dW1 = x_flat.T @ dlogits  # (T*C, vocab)\n",
        "    dx_flat = dlogits @ W1.T  # (B, T*C)\n",
        "    dx_emb = dx_flat.reshape(x_emb.shape)  # (B, T, C)\n",
        "\n",
        "    # Градиент по эмбеддингам\n",
        "    d_token_embedding = np.zeros_like(token_embedding_table)\n",
        "    for i in range(X.shape[0]):\n",
        "        for t in range(block_size):\n",
        "            idx = X[i, t]\n",
        "            d_token_embedding[idx] += dx_emb[i, t]\n",
        "\n",
        "    # Обновление весов\n",
        "    W1 -= learning_rate * dW1\n",
        "    token_embedding_table -= learning_rate * d_token_embedding\n"
      ],
      "metadata": {
        "id": "N4eyqvyEv8fC",
        "outputId": "ffab0aa7-d23c-474d-9a87-b5ca00f5ce73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0 | Loss: 1.3864\n",
            "Epoch  50 | Loss: 1.3286\n",
            "Epoch 100 | Loss: 0.3958\n",
            "Epoch 150 | Loss: 0.0797\n",
            "Epoch 200 | Loss: 0.0347\n",
            "Epoch 250 | Loss: 0.0207\n",
            "Epoch 300 | Loss: 0.0143\n",
            "Epoch 350 | Loss: 0.0107\n",
            "Epoch 400 | Loss: 0.0085\n",
            "Epoch 450 | Loss: 0.0070\n",
            "Epoch 499 | Loss: 0.0059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Генерация"
      ],
      "metadata": {
        "id": "mFEG_IeYwBIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(context, max_new_tokens=20):\n",
        "    context = context[-block_size:]\n",
        "    generated = context[:]\n",
        "    for _ in range(max_new_tokens):\n",
        "        x = np.array([generated[-block_size:]])  # (1, T)\n",
        "        x_emb = token_embedding_table[x]  # (1, T, C)\n",
        "        x_flat = x_emb.reshape(1, -1)  # (1, T*C)\n",
        "        logits = x_flat @ W1  # (1, vocab)\n",
        "        probs = np.exp(logits - np.max(logits))\n",
        "        probs = probs / probs.sum()\n",
        "        next_token = np.random.choice(vocab_size, p=probs.ravel())\n",
        "        generated.append(next_token)\n",
        "    return decode(generated)"
      ],
      "metadata": {
        "id": "sCWKnA-nwD2s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод"
      ],
      "metadata": {
        "id": "Yf2NAqM3wEor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Сгенерированный текст:\", generate(encode(\"hell\")))"
      ],
      "metadata": {
        "id": "8atC-qkXwHfT",
        "outputId": "f638e5cb-35bc-46e8-951f-8fba63401d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сгенерированный текст: hellohellohellohellohell\n"
          ]
        }
      ]
    }
  ]
}