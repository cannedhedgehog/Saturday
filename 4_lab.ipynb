{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdRUmQzbMf/SLHmYGdFbRT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cannedhedgehog/Saturday/blob/main/4_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ShvEFCSad_S2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Активационные функции"
      ],
      "metadata": {
        "id": "5qbncUoOeDk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "uJzgT-ljeEGV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Простая нейронная сеть"
      ],
      "metadata": {
        "id": "QkNnw3P1eHDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
        "        self.weights_hidden_output = np.random.randn(hidden_size, 1)\n",
        "        self.bias_hidden = np.zeros((1, hidden_size))\n",
        "        self.bias_output = np.zeros((1, 1))\n",
        "\n",
        "    def feedforward(self, X):\n",
        "        X = np.atleast_2d(X)\n",
        "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_output = sigmoid(self.hidden_input)\n",
        "        self.final_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "        return sigmoid(self.final_input)\n",
        "\n",
        "    def train(self, X, y, epochs=1000, lr=0.1, print_every=100):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.feedforward(X)\n",
        "            error = y - output\n",
        "            loss = np.mean(error ** 2)\n",
        "\n",
        "            if epoch % print_every == 0 or epoch == epochs - 1:\n",
        "                print(f\"Epoch {epoch:5d} | Loss: {loss:.6f}\")\n",
        "\n",
        "            d_output = error * sigmoid_derivative(output)\n",
        "            error_hidden = d_output.dot(self.weights_hidden_output.T)\n",
        "            d_hidden = error_hidden * sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "            self.weights_hidden_output += self.hidden_output.T.dot(d_output) * lr\n",
        "            self.weights_input_hidden += X.T.dot(d_hidden) * lr\n",
        "            self.bias_output += np.sum(d_output, axis=0, keepdims=True) * lr\n",
        "            self.bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * lr"
      ],
      "metadata": {
        "id": "mBkAK4UseKRH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Упрощённый трансформер (GPT-подобная модель)"
      ],
      "metadata": {
        "id": "ZBRUmK_FeOWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTransformer:\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embeddings = np.random.randn(vocab_size, embedding_dim)\n",
        "\n",
        "    def encode(self, input_sequence):\n",
        "        return np.array([self.embeddings[token] for token in input_sequence])\n",
        "\n",
        "    def decode(self, encoded_sequence):\n",
        "        return [np.argmax(np.dot(self.embeddings, vec)) for vec in encoded_sequence]\n",
        "\n",
        "    def forward(self, input_sequence):\n",
        "        encoded = self.encode(input_sequence)\n",
        "        return self.decode(encoded)"
      ],
      "metadata": {
        "id": "qKwvCAOReRZv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тестирование нейронной сети (XOR)"
      ],
      "metadata": {
        "id": "BE4Pdat0eVje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "nn = NeuralNetwork(input_size=2, hidden_size=4)\n",
        "nn.train(X, y, epochs=5000, lr=0.1, print_every=500)\n",
        "\n",
        "print(\"\\nТестирование обученной сети:\")\n",
        "for input_data, target in zip(X, y):\n",
        "    prediction = nn.feedforward(input_data)\n",
        "    print(f\"Вход: {input_data} | Ожидаемый: {target[0]} | Предсказанный: {prediction[0][0]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMLgWBXWeaUZ",
        "outputId": "a132b37d-13e8-4a09-924f-8099434f38ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch     0 | Loss: 0.349056\n",
            "Epoch   500 | Loss: 0.226109\n",
            "Epoch  1000 | Loss: 0.138216\n",
            "Epoch  1500 | Loss: 0.052952\n",
            "Epoch  2000 | Loss: 0.024835\n",
            "Epoch  2500 | Loss: 0.014842\n",
            "Epoch  3000 | Loss: 0.010219\n",
            "Epoch  3500 | Loss: 0.007660\n",
            "Epoch  4000 | Loss: 0.006068\n",
            "Epoch  4500 | Loss: 0.004995\n",
            "Epoch  4999 | Loss: 0.004229\n",
            "\n",
            "Тестирование обученной сети:\n",
            "Вход: [0 0] | Ожидаемый: 0 | Предсказанный: 0.0489\n",
            "Вход: [0 1] | Ожидаемый: 1 | Предсказанный: 0.9348\n",
            "Вход: [1 0] | Ожидаемый: 1 | Предсказанный: 0.9337\n",
            "Вход: [1 1] | Ожидаемый: 0 | Предсказанный: 0.0766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тестирование упрощённого трансформера"
      ],
      "metadata": {
        "id": "Cf3a37qAed5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {chr(i + 97): i for i in range(26)}\n",
        "inv_vocab = {i: chr(i + 97) for i in range(26)}\n",
        "\n",
        "input_sequence = [vocab[char] for char in \"hello\"]\n",
        "\n",
        "model = SimpleTransformer(vocab_size=26, embedding_dim=16)\n",
        "output_sequence = model.forward(input_sequence)\n",
        "output_chars = [inv_vocab[idx] for idx in output_sequence]\n",
        "\n",
        "print(\"\\nРезультат работы трансформера:\")\n",
        "print(\"\".join(output_chars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "631CEcXjekGy",
        "outputId": "5ce209a5-4389-461a-fee0-ab68d14ec7fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Результат работы трансформера:\n",
            "hello\n"
          ]
        }
      ]
    }
  ]
}